---
title: "Sample size and duration of follow-up of randomized controlled clinical trials"
author:
  - Tamás Ferenci (tamas.ferenci@medstat.hu)
date: "<br>17 April, 2025"
output:
  github_document:
    toc: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, out.width = "100%",
                      dpi = 300, dev = "ragg_png")
```

## Motivation

Randomized controlled trials (RCTs) are commonly referred to as the "gold standard" for establishing the safety and efficacy of a drug, and are now almost universally required for obtaining marketing authorization for new pharmaceuticals. This designation is well-earned: through randomization, RCTs can theoretically ensure that there are *no* systematic differences between the groups being compared -- aside from their exposure to the drug. As a result, any observed differences in outcomes -- whether beneficial effects (efficacy) or adverse effects (safety) -- can be confidently attributed to the drug itself (alongside random variability, which can be addressed statistically). In other words, there is no [confounding](https://www.annualreviews.org/content/journals/10.1146/annurev.publhealth.22.1.189).

The key phrase here is "at all": randomization implies no differences even in unknown or unmeasured variables -- even in factors we are not aware could act as confounders. This stands in sharp contrast to observational studies, where we can only adjust for *known and measured* confounders. These can be managed through design strategies like restriction, or analytical methods such as stratification or regression adjustment. However, these approaches are only effective for variables we recognize as confounders and for which we have collected data (and even then, limitations might remain, for example, the number of confounders we can adjust for is constrained by the study’s sample size). This is the most important strength of RCTs: their potential to eliminate bias from confounding, giving them unique power in evaluating drug effects.

The "theoretically" part is equally important: RCTs can be poorly designed or executed, even in ways that reintroduce just the confounding. Randomization failures, improper blinding, protocol deviations etc. commonly appear in practice. However, they at least offer the theoretical possibility of being free of confounding in a sense of having zero bias due to it -- in an observational study we can never say, not even theoretically, that there is "surely" no confounding.

That said, RCTs also have important limitations, two of which will be examined here. First, RCTs typically have smaller *sample sizes* than observational studies. The latter can often include sample sizes orders of magnitude larger (and achieving the same sample size is also more feasible with an observational study). Second, RCTs usually have much shorter *duration of follow-up* than observational studies. Together, these limitations mean that RCTs tend to have lower *statistical power*. This means that small effects -- whether small desired effects, or rare side effects -- may be harder to detect in RCTs. (Side effects with delayed onset -- i.e., those that only emerge after a certain period of time rather than accumulating linearly -- are harder to detect in RCTs, due to the limited follow-up.)

But how significant is this limitation in practice? To explore this, it is instructive to look at how large and how long RCTs can actually be. We will investigate this using data from ClinicalTrials.gov.

The US National Library of Medicine’s ClinicalTrials.gov registry (<https://clinicaltrials.gov/>) is a comprehensive [database](https://clinicaltrials.gov/about-site/about-ctg) of RCTs, launched in 2000. While submission is mandatory for trials regulated by the FDA, sponsors and investigators from outside the US can also register their studies. Because of its international recognition and scope, the vast majority of significant RCTs are submitted to ClinicalTrials.gov. This makes it an excellent resource for constructing a broad and detailed picture of contemporary trials, both geographically (covering studies worldwide) and temporally (spanning several decades). It is also important that the database of ClinicalTrials.gov is publicly accessible.

However, it's important to acknowledge a key limitation: while ClinicalTrials.gov likely captures nearly all relevant modern trials, it does not include historical studies conducted before its inception. Case in point, probably the largest RCT ever conducted was the [1954 field trial](https://ajph.aphapublications.org/toc/ajph.1/45/5_Pt_2) of the inactived polio vaccine of Jonas Salk which involved 400,000 children randomized. We will miss this study and similar historical ones, but nonetheless, we can safely say that ClinicalTrials.gov allows us to comprehensively examine the "modern era" of drug trials.

We will use the [R environment for statistical computing](https://www.r-project.org/) to carry out the data downloading, extraction and analysis using packages `data.table` and `ggplot2` among others:

```{r}
library(data.table)
library(ggplot2)
theme_set(theme_bw())
```

## Data extraction

ClinicalTrials.gov has a [comfortable API](https://clinicaltrials.gov/data-api/api) to query its database. To use it, the first step is to create an appropriate query string. We will use the [following filters](https://clinicaltrials.gov/data-api/about-api/search-areas):

- `StudyType` will be set to `INTERVENTIONAL` and `DesignAllocation` will be set to `RANDOMIZED` to ensure that we only capture RCTs.
- `EnrollmentType` will be set to `ACTUAL`, as we will very much use enrollment data later, so it is important that this reflects actual (not estimated) enrollment.
- `DesignPrimaryPurpose` will be set to `TREATMENT OR PREVENTION` and `InterventionType` will be set to `DRUG OR BIOLOGICAL` to capture only drug trials.
- `overallStatus` will be set to `COMPLETED` to capture only completed trials.

[Putting this together](https://clinicaltrials.gov/find-studies/constructing-complex-search-queries) results in the following query string:

```{r}
qrystring <- paste0(
  "https://clinicaltrials.gov/api/v2/studies?format=csv&",
  "query.term=AREA%5BStudyType%5DINTERVENTIONAL+AND+",
  "AREA%5BDesignAllocation%5DRANDOMIZED+AND+",
  "AREA%5BEnrollmentType%5DACTUAL+AND+AREA",
  "%5BDesignPrimaryPurpose%5D%28TREATMENT+OR+PREVENTION%29&",
  "query.intr=AREA%5BInterventionType%5D%28DRUG+OR+",
  "BIOLOGICAL%29&filter.overallStatus=COMPLETED&pageSize=1000"
)
```

Actually querying ClinicalTrials.gov is not complicated using its API, the only thing we have to track is the `x-next-page-token`. (This should not be given for the first query, but should be given to any subsequent one based on the response of the previous query. The last query is indicated by the lack of `x-next-page-token` in the response header.) We will use the CSV format which somewhat [limits our possibilities](https://clinicaltrials.gov/data-api/about-api/csv-download), but it'll be sufficient for our purpose and it is very easy to handle in R:

```{r}
res <- curl::curl_fetch_memory(qrystring)
RawData <- fread(rawToChar(res$content), check.names = TRUE)
npt <- fread(rawToChar(res$headers), fill = TRUE)[
  V1 == "x-next-page-token:"]$V2
while(length(npt) != 0) {
  res <- curl::curl_fetch_memory(paste0(qrystring, "&pageToken=",
                                        npt))
  RawData <- rbind(RawData, fread(rawToChar(res$content)),
                   use.names = FALSE)
  npt <- fread(rawToChar(res$headers), fill = TRUE)[
    V1 == "x-next-page-token:"]$V2
}
```

One problem is that the results will include not only individually randomized, but also cluster-randomized trials. We now try to focus only on individually randomized trials, so let's try to remove cluster-randomized trials:

```{r}
RawData <- RawData[!grepl("cluster-randomized", Brief.Summary)]
RawData <- RawData[!grepl("cluster randomized", Brief.Summary)]
RawData <- RawData[!grepl("cluster randomised", Brief.Summary)]
```

This is unfortunately not perfect, so some cluster-randomized trials slip through. We can manually remove these (with a pointer here to the source where the cluster-randomized nature can be seen):

```{r}
RawData <- RawData[
  !NCT.Number %in%
    c("NCT02027207", # 10.1016/j.vaccine.2013.10.021
      "NCT04424511", # clinicaltrials.gov
      "NCT00269542", # 10.1093/jn/137.1.112
      "NCT00289224" # 10.1016/S0140-6736(09)61297-6
    )]
```

The `StudyDesign` field contains information on the study design, but unfortunately within a single field. Luckily its content is structured, so we can separate the parts:

```{r}
temp <- rbindlist(lapply(lapply(strsplit(
  RawData$Study.Design, "[|:]+"), trimws), as.list))
# apply(temp, 2, table)
RawData$Allocation <- temp$V2
RawData$InterventionModel <- temp$V4
RawData$Masking <- temp$V6
RawData$PrimaryPurpose <- temp$V8
```

It might be useful to introduce a less detailed masking information variable:

```{r}
RawData$MaskingSimple <- ifelse(RawData$Masking == "", NA,
                                trimws(sapply(strsplit(
                                  RawData$Masking, "(",
                                  fixed = TRUE), `[`, 1)))
```

Whether the trial was controlled with placebo (as opposed to active control) can be likely detected from the `Interventions` field by checking whether it includes the term placebo:

```{r}
RawData$Placebo <- grepl("placebo", RawData$Interventions,
                         ignore.case = TRUE)
```

This provides us with the information on the sample size, as this is just one of the fields we have downloaded (with the name `Enrollment`). Obtaining the duration of the follow-up is however far more complicated.

The fundamental problem is that -- in contrast to sample size -- duration of follow-up is not stored as a separate, well-defined, machine-processable field. The best we have is that among results, for each outcome there is a field called "time frame", which we can utilize -- with several limitations. First, it'll be only available for trials that have results posted. Second, the content of this field is still a non-structured verbal description, hence durations need to be extracted with text mining, which can never be perfect. Finally, this doesn't actually informs us on the concrete follow-up, rather, as the name suggests, it simply specifies a time frame for the given outcome. At best, this can be considered to be a proxy for actual follow-up, but it has to be emphasized again, that -- in contrast to the sample size -- this will be only a rough measure.

As these fields are available only among the results, we have to individually download it for each study:

```{r}
RawDataTimes <- lapply(RawData[
  Study.Results == "YES"]$NCT.Number, function(nct)
    jsonlite::fromJSON(rawToChar(curl::curl_fetch_memory(paste0(
      "https://clinicaltrials.gov/api/v2/studies/", nct,
      "?fields=resultsSection.outcomeMeasuresModule.",
      "outcomeMeasures.timeFrame"))$content))$resultsSection$
    outcomeMeasuresModule$outcomeMeasures$timeFrame)
```

Once we have the information, the duration has to be extracted. First, as it is usually done, we convert everything to lower case to simplify the subsequent steps:

```{r}
RawDataTimes <- lapply(RawDataTimes, tolower)
```

Then we convert numbers given as text to numbers (by a very simple replacement from 1 to 100, paying attention only to matching just standalone words, not parts of a word):

```{r}
RawDataTimes <- lapply(RawDataTimes, textclean::mgsub,
                       pattern =
                         paste0(" ",
                                textclean::replace_number(1:100),
                                " "),
                       replacement = 1:100)
```

Finally, we carry out the extraction using a regular expression that matches two patterns: a number (possibly with decimal part) followed by a text that points to a duration (e.g., "2.5 years" or "1 month"), or a specifier that points to a duration followed by a number without decimal part (e.g., "Day 30" or "Month 2"):

```{r}
qrypattern <- paste0(
  "\\b\\d{1,3}((\\.|\\,)\\d{1,3})?\\s*(day|days|week|weeks|month",
  "|months|hour|hours|min|mins|minute|minutes|year|years|yr|yrs)",
  "\\b|\\b(day|week|month|year)\\s*\\d{1,3}\\b")
```

We convert the extracted durations uniformly to days:

```{r}
convtime <- function(x) {
  value <- as.numeric(stringr::str_extract(
    gsub(",", ".", x, fixed = TRUE), "\\d{1,3}(.\\d{1,3})?"))
  unit <- stringr::str_extract(x,
                               "day|week|month|hour|min|year|yr")
  value * switch(unit,
                 "day" = 1, "week" = 7, "month" = 30,
                 "hour" = 1/24, "min" = 1/3600, "year" = 365,
                 "yr" = 365)
}
```

The strategy will be that we extract every suspected duration that we can, and -- after converting them to days -- we simply take the largest one. This is arguable, but probably the best we can do to capture the whole length of the trial:

```{r}
extrconv <- function(x) {
  res <- lapply(unlist(stringr::str_extract_all(
    x[!is.na(x)], pattern = qrypattern)), convtime)
  if(length(res) == 0) NA else max(sapply(res, max, na.rm = TRUE),
                                   na.rm = TRUE)
}
```

We can now merge these data with the original database:

```{r}
RawData <- merge(RawData, data.table(
  NCT.Number = RawData[Study.Results == "YES"]$NCT.Number,
  EstFU = sapply(RawDataTimes, extrconv)),
  all.x = TRUE, sort = FALSE)
```

Unfortunately, this is still not perfect: some trials have a time frame like "During the 7-day (Days 0-6) post-vaccination period following each dose and across doses, for subjects between 18-64 years of age", where the age will be captured as duration. We now just manually erase these:

```{r}
RawData[NCT.Number %in%
          c("NCT00985088", "NCT00534638", "NCT01857206",
            "NCT01244490")]$EstFU <- NA
```

Let's save these results to facilitate processing:

```{r}
fwrite(RawData, "ClinicalTrialsGov-data.csv")
saveRDS(RawData, "ClinicalTrialsGov-data.rds")
```

Thus, it'll be available both in CSV and in RDS formats.

Finally, as later we will often use only the blinded, placebo-controlled RCTs, let's collect them into a separate data table:

```{r}
RawData2 <- RawData[Masking != "NONE" & Placebo == TRUE]
```

## Sample sizes

First, lets start with visualizing the distribution of the sample sizes (note that the horizontal scale is logarithmic!):

```{r}
ggplot(RawData[Enrollment > 0], aes(x = Enrollment)) +
  geom_histogram(color = "black", fill = "white", bins = 30) +
  scale_x_log10(breaks = scales::breaks_log(n = 6),
                labels = scales::label_comma(),
                guide = "axis_logticks") +
  labs(y = "Count")
```

A few noteworthy quantiles:

```{r}
ps <- c(0.5, 0.75, 0.9, 0.99, 0.999)
knitr::kable(data.table(`Percentile` = ps * 100,
                        `Sample size` =
                          quantile(RawData$Enrollment, ps)),
             digits = c(1, 0))
```

Or, the other way around, a few noteworthy points of the cumulative distribution function:

```{r}
ns <- c(0.01, 0.02, 0.05, 0.1, 0.2, 0.5,
        1, 2, 5, 10, 20, 50) * 1e3
knitr::kable(data.table(`Sample size` = ns,
                        `Proportion of trials smaller [%]` =
                          sapply(ns, function(n)
                            mean(RawData$Enrollment < n) * 100)),
             digits = c(0, 2))
```

Returning to the visualizations, it might be interesting to compare different types. For example, the distribution according to whether the comparator is placebo or not:

```{r}
ggplot(RawData[Enrollment > 0], aes(x = Enrollment)) +
  geom_density(aes(group = Placebo, color = Placebo)) +
  scale_x_log10(breaks = scales::breaks_log(n = 6),
                labels = scales::label_comma(),
                guide = "axis_logticks") +
  labs(y = "Count")
```

Now we can have a look at the few largest trials:

```{r}
knitr::kable(RawData[
  order(Enrollment, decreasing = TRUE),
  .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo, Age,
    Enrollment)][1:10])
```

Restring ourselves only to placebo-controlled, blinded RCTs:

```{r}
knitr::kable(RawData2[
  order(Enrollment, decreasing = TRUE),
  .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo, Age,
    Enrollment)][1:10])
```

And those that involved only children:

```{r}
knitr::kable(RawData2[Age == "CHILD"][
  order(Enrollment, decreasing = TRUE),
  .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo, Age,
    Enrollment)][1:10])
```

## Duration of follow-up

Emphasizing again that this is just a rough estimate, let's now visualize the distribution of the duration of the follow-up (for studies where it was more than 0.1 days):

```{r}
ggplot(RawData[!is.na(EstFU) & EstFU > 0.1], aes(x = EstFU)) +
  geom_histogram(color = "black", fill = "white", bins = 20) +
  scale_x_log10(breaks = scales::breaks_log(n = 6),
                labels = scales::label_comma(),
                guide = "axis_logticks") +
  labs(x = "Estimated duration of follow-up [days]", y = "Count")
```

A few noteworthy quantiles:

```{r}
ps <- c(0.5, 0.75, 0.9, 0.99, 0.999)
knitr::kable(data.table(`Percentile` = ps * 100,
                        `Duration of follow-up` =
                          quantile(RawData$EstFU, ps,
                                   na.rm = TRUE)),
             digits = c(1, 0))
```

Or, the other way around, a few noteworthy points of the cumulative distribution function:

```{r}
durs <- c(0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000, 5000)
knitr::kable(data.table(`Duration of follow-up` = durs,
                        `Proportion of trials shorter [%]` =
                          sapply(durs, function(dur)
                            mean(RawData$EstFU < dur,
                                 na.rm = TRUE) * 100)),
             digits = c(0, 2))
```

Now we can have a look at the few longest trials:

```{r}
knitr::kable(RawData[
  order(EstFU, decreasing = TRUE),
  .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo, Age,
    EstFU)][1:10])
```

Restring ourselves only to place-controlled, blinded RCTs:

```{r}
knitr::kable(RawData2[
  order(EstFU, decreasing = TRUE),
  .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo, Age,
    EstFU)][1:10])
```

And those that involved only children:

```{r}
knitr::kable(RawData2[Age == "CHILD"][
  order(EstFU, decreasing = TRUE),
  .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo, Age,
    EstFU)][1:10])
```

## Miscellaneous

### Relationship of sample size and follow-up duration

It is interesting to check if there is any relationship between the sample size and the duration of the follow-up:

```{r}
ggplot(RawData[Enrollment > 0 & !is.na(EstFU) & EstFU > 0.1],
       aes(x = Enrollment, y = EstFU)) +
  geom_point(size = 0.1, alpha = 0.3) +
  scale_x_log10(breaks = scales::breaks_log(n = 6),
                labels = scales::label_comma(),
                guide = "axis_logticks") +
  scale_y_log10(breaks = scales::breaks_log(n = 6),
                labels = scales::label_comma(),
                guide = "axis_logticks") +
  geom_smooth(method = "gam", formula = y ~ s(x, bs = "cs")) +
  labs(y = "Estimated duration of follow-up [days]")
```

### Person-years

Given the uncertainty in the estimation of the follow-up duration, this is also somewhat approximate, but let's check what trials had the largest follow-up in terms of person-years:

```{r}
RawData$PY <- RawData$Enrollment * RawData$EstFU
knitr::kable(
  RawData[order(PY, decreasing = TRUE),
          .(NCT.Number, Study.URL, Phases, MaskingSimple, Placebo,
            Age, Enrollment, EstFU, PY/1e6)][1:10])
```

## Further development possibilities

- Better identification of cluster-randomized trials.
- Better identification of placebo control.
- Better extraction of the durations from the `outcomeMeasures.timeFrame` fields.
- More investigations of the possible predictors (such as the placebo-control done above). 